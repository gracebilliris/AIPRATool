# AI Privacy Risk Assessment (AIPRA) Tool

Welcome to the **AI Privacy Risk Assessment Tool (AIPRA Tool)!**  
This tool helps organisations evaluate privacy risks associated with their Multi-Agent AI systems. By completing this assessment, you can identify potential privacy risks, evaluate existing controls, and prioritise areas for improvement.

---

## System Type

**What type of system are you assessing?**  
_Select one to reveal the system definition._

<details>
  <summary><strong>AI System</strong></summary>
  
  AI refers to the simulation of human intelligence processes by machines, particularly systems capable of learning, reasoning, and decision-making (Billiris et al. 2024; Lee et al. 2024).
</details>

---

## Privacy Risk Assessment Questions

### Governance & Risk Management

**1. How does the governance structure address the integration of data privacy concerns in Multi-Agent AI systems?**

-   **High:** Regularly (e.g., quarterly or per release)
-   **Moderate:** Occasionally (ad hoc or only for major changes)
-   **Low:** Rarely or no formal review conducted

**2. How regularly is your systemâ€™s privacy risk assessed or reviewed?**

-   **High:** Regularly scheduled assessments
-   **Moderate:** Occasional or reactive assessments
-   **Low:** Rarely or no assessments

---

### Privacy Risk Assessment

**3. Have you identified all personal and sensitive data collected by the system?**

-   **High:** Fully mapped and documented all types of data
-   **Moderate:** Some data identified, others unclear
-   **Low:** No formal data mapping

**4. Have you assessed re-identification, aggregation, or inference risks?**

-   **High:** Actively monitored and managed risks
-   **Moderate:** Considered in part, but not consistently
-   **Low:** Not yet assessed or managed

---

### Privacy Controls Implementation

**5. Are privacy-preserving techniques (e.g., differential privacy, encryption, federated learning) implemented?**

-   **High:** Fully implemented and maintained
-   **Moderate:** Some techniques in place, but not consistently
-   **Low:** No techniques implemented

**6. Are data minimisation and purpose limitation enforced?**

-   **High:** Strictly enforced with only necessary data collected
-   **Moderate:** Principles applied inconsistently
-   **Low:** Little attention to minimisation

---

### User-Centric Privacy Considerations

**7. Are users informed about data collection and use (transparency)?**

-   **High:** Clear, easy-to-understand privacy notices available
-   **Moderate:** Vague or difficult-to-access information
-   **Low:** No clear communication on data use

**8. Can users control their data (e.g., consent, access, deletion)?**

-   **High:** Self-service tools or clear, accessible processes in place
-   **Moderate:** Limited options for users to control their data
-   **Low:** No control mechanisms available to users

---

### Continuous Monitoring & Improvement

**9. How frequently is the system updated to reflect new privacy risks or regulations?**

-   **High:** Regularly, with processes in place to adapt to changes
-   **Moderate:** Occasionally, addressed reactively
-   **Low:** Rarely, with minimal updates

**10. Are privacy audits or third-party reviews conducted?**

-   **High:** Regular, documented audits and external reviews
-   **Moderate:** Some informal reviews conducted
-   **Low:** No audits or external reviews

---

_Note:_ This tool is in its initial development phase and serves as a proof of concept for guiding privacy risk awareness. Results should be interpreted as general guidance, not definitive legal or compliance assessments. Further refinements are ongoing.
